# This is my self learning progression for AI/ML:

- Learnt about np.random.seed - > Pseudo-random numbers
- The differences between Gaussian distribution/normal distribution/univariate distribution and multivariate distribution
- Link function -> Sigmoid function to convert real numbers to a probability
- Log-likelihood -> It measures how well a particular model fits the data.
- Calculated the gradient -> bit's the derivative of the log-likelihood equation then reform to matrix form.
- sk-learn logistic regression -> is more accuracte and should use it instead
- Accuracy -> get the accuracy by using the final weights, then use sigmoid to get final predictions, round it up to nearest integer (0 or 1) to get the prediction class.
- Incorrect predictions -> are mostly in the middle between the clusters

Website that I followed
 https://beckernick.github.io/logistic-regression-from-scratch/ (main)
 https://www.kdnuggets.com/2019/10/build-logistic-regression-model-python.html (partial)
